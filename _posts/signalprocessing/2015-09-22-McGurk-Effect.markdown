---
layout: article
title:  McGurk Effect
date:   2015-09-22 
categories: [signalprocessing]
image:
    teaser: men_talking.png
author: sira_ferradans
---

It is well known that our brain is able merge different kinds of information to get a better understanding of the world. For instance, in a party, with much noise, the brain uses the visual information given by the motion of the lips, together with the auditive information to better understand the person that is speaking. But in some cases, our perception of the sound might change just with a change in the image.

A nice example of this is the '[McGurk Effect][McGurkEffect]', that shows that our brain 'hears' what it sees. You can see an example here:

<iframe width="656" height="369" src="https://www.youtube.com/embed/G-lN8vWm3m0" frameborder="0" allowfullscreen></iframe>

The idea is that, when looking at somebody talking, the sound that we understand is in accordance with what we see. So, if the image is changed, but not the sound, our perception of the sound changes. 

 

[McGurkEffect]: http://www.nature.com/nature/journal/v264/n5588/abs/264746a0.html